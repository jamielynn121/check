{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Stop Sign Behavior\"\nauthor: \"David Holt\"\ndate: \"12/04/2018\"\noutput: github_document\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(tidyverse)\n#setwd(\"~/Dropbox/Projects/turning/\")\ndata <- readxl::read_xlsx(\"Project Data.xlsx\")\n```\n\n## Data\n\nI collected this data during a two hour period at a stop sign in Knoxville, TN, in 2017. It encodes information about each car that approached the stop sign, including how long they stopped at the sign, the direction they turned, the sex of the driver, the type of vehicle, the race of the driver (if obvious), whether or not they were on their phone or actively looking at their phone, how many passengers they had, whether or not it was a commercially marked vehicle, if the driver seemed to be over 50 years old, if there was another vehicle at the stop sign, if a police vehicle was present, whether or not they used their blinker, and any additional information.\n\n## Methodology\n\nI am following the clustering methodology used by Anastasia Reusova at https://medium.com/@anastasia.reusova/hierarchical-clustering-on-categorical-data-in-r-a27e578f2995.\n\n## Clustering drivers\n\n```{r}\n#----- Dissimilarity Matrix -----#\n\nlibrary(cluster) \n# to perform different types of hierarchical clustering\n# package functions used: daisy(), diana(), clusplot()\n\ndata_clean <- \n  data %>%\n  mutate(direction = factor(direction),\n         driversex = factor(driversex),\n         cartype = factor(cartype),\n         race = factor(race),\n         phoneuse = as.logical(phoneuse),\n         commercial = as.logical(commercial),\n         older = as.logical(older),\n         traffic = as.logical(traffic),\n         policepresent = as.logical(policepresent),\n         blinker = as.logical(blinker)) %>%\n  select(-order, -comments, -time)\n\ngower.dist <- daisy(data_clean, metric = c(\"gower\"))\n\n#------------ DIVISIVE CLUSTERING ------------#\ndivisive.clust <- diana(as.matrix(gower.dist), \n                  diss = TRUE, keep.diss = TRUE)\nplot(divisive.clust, main = \"Divisive\")\n\n\n```\n\n```{r}\n#------------ AGGLOMERATIVE CLUSTERING ------------#\n# I am looking for the most balanced approach\n# Complete linkages is the approach that best fits this demand - I will leave only this one here, don't want to get it cluttered\n\n# complete\naggl.clust.c <- hclust(gower.dist, method = \"complete\")\nplot(aggl.clust.c,\n     main = \"Agglomerative, complete linkages\")\n```\n\n```{r}\nlibrary(fpc)\n\ncstats.table <- function(dist, tree, k) {\nclust.assess <- c(\"cluster.number\",\"n\",\"within.cluster.ss\",\"average.within\",\"average.between\",\n                  \"wb.ratio\",\"dunn2\",\"avg.silwidth\")\nclust.size <- c(\"cluster.size\")\nstats.names <- c()\nrow.clust <- c()\n\noutput.stats <- matrix(ncol = k, nrow = length(clust.assess))\ncluster.sizes <- matrix(ncol = k, nrow = k)\n\nfor(i in c(1:k)){\n  row.clust[i] <- paste(\"Cluster-\", i, \" size\")\n}\n\nfor(i in c(2:k)){\n  stats.names[i] <- paste(\"Test\", i-1)\n  \n  for(j in seq_along(clust.assess)){\n    output.stats[j, i] <- unlist(cluster.stats(d = dist, clustering = cutree(tree, k = i))[clust.assess])[j]\n    \n  }\n  \n  for(d in 1:k) {\n    cluster.sizes[d, i] <- unlist(cluster.stats(d = dist, clustering = cutree(tree, k = i))[clust.size])[d]\n    dim(cluster.sizes[d, i]) <- c(length(cluster.sizes[i]), 1)\n    cluster.sizes[d, i]\n    \n  }\n}\n\noutput.stats.df <- data.frame(output.stats)\n\ncluster.sizes <- data.frame(cluster.sizes)\ncluster.sizes[is.na(cluster.sizes)] <- 0\n\nrows.all <- c(clust.assess, row.clust)\noutput <- rbind(output.stats.df, cluster.sizes)[ ,-1]\ncolnames(output) <- stats.names[2:k]\nrownames(output) <- rows.all\n\nis.num <- sapply(output, is.numeric)\noutput[is.num] <- lapply(output[is.num], round, 2)\n\noutput\n}\n```\n\n```{r}\nstats.df.aggl <-cstats.table(gower.dist, aggl.clust.c, 7) \nstats.df.aggl\n```\n\n```{r}\nggplot(data = data.frame(t(cstats.table(gower.dist, aggl.clust.c, 15))), \n  aes(x=cluster.number, y=avg.silwidth)) + \n  geom_point()+\n  geom_line()+\n  ggtitle(\"Agglomerative clustering\") +\n  labs(x = \"Num.of clusters\", y = \"Average silhouette width\") +\n  theme(plot.title = element_text(hjust = 0.5))\n```\n\n```{r}\nlibrary(\"ggplot2\")\nlibrary(\"reshape2\")\nlibrary(\"purrr\")\nlibrary(\"dplyr\")\nlibrary(\"dendextend\")\n\ndendro <- as.dendrogram(aggl.clust.c)\n\ndendro.col <- dendro %>%\n  set(\"branches_k_color\", k = 3, value =   c(\"darkslategray\", \"darkslategray4\", \"darkslategray3\")) %>%\n  set(\"branches_lwd\", 0.6) %>%\n  set(\"labels_colors\", \n      value = c(\"darkslategray\")) %>% \n  set(\"labels_cex\", 0.5)\n\nggd1 <- as.ggdend(dendro.col)\n\nggplot(ggd1, theme = theme_minimal()) +\n  labs(x = \"Num. observations\", y = \"Height\", title = \"Dendrogram, k = 3\")\n```\n\n```{r}\nggplot(ggd1, labels = T) + \n  scale_y_reverse(expand = c(0.2, 0)) +\n  coord_polar(theta=\"x\")\n```\n  \n```{r}\nclust.num <- cutree(aggl.clust.c, k = 3)\ndata_clean.cl <- cbind(data_clean, clust.num)\n\ncust.long <- melt(data.frame(id.s = data$order, lapply(data_clean.cl, as.character), stringsAsFactors=FALSE), id = c(\"id.s\", \"clust.num\"), factorsAsStrings=T)\n\ncust.long.q <- cust.long %>%\n  group_by(clust.num, variable, value) %>%\n  mutate(count = n_distinct(id.s)) %>%\n  distinct(clust.num, variable, value, count)\n\n# heatmap.c will be suitable in case you want to go for absolute counts - but it doesn't tell much to my taste\n\ncust.long.q$value <- factor(cust.long.q$value)\nlevels(cust.long.q$value) <- c(\"No Passengers\", \"1 Passenger\", \"2 Passengers\", \"4 Passengers\", \n                               \"African American\", \"Asian\", \"Caucasian\", \"Car\", \"Phone In Use\",\n                               \"Female\", \"Hispanic\", \"Left Turn\", \"Male\", \"Middle-Eastern\", \n                               \"Right Turn\", \"SUV\", \"Truck\", \"Police Present\", \"Van\")\n  \nheatmap.c <- ggplot(cust.long.q, aes(x = clust.num, y = value)) +\n  geom_tile(aes(fill = count))+\n  scale_fill_gradient2(low = \"darkslategray1\", mid = \"yellow\", high = \"turquoise4\")\nheatmap.c\n```\n\n\n```{r}\n# calculating the percent of each factor level in the absolute count of cluster members\ncust.long.p <- cust.long.q %>%\n  group_by(clust.num, variable) %>%\n  mutate(perc = count / sum(count)) %>%\n  arrange(clust.num)\n\nheatmap.p <- ggplot(cust.long.p, aes(x = clust.num, y = value)) +\n  \ngeom_tile(aes(fill = perc), alpha = 0.85)+\n  labs(title = \"Distribution of characteristics across clusters\", x = \"Cluster number\", y = NULL) +\n  geom_hline(yintercept = 3.5) + \n  geom_hline(yintercept = 10.5) + \n  geom_hline(yintercept = 13.5) + \n  geom_hline(yintercept = 17.5) + \n  geom_hline(yintercept = 21.5) + \n  scale_fill_gradient2(low = \"darkslategray1\", mid = \"yellow\", high = \"turquoise4\")\n\nheatmap.p\n```\n\n```{r}\ndata$cluster <- data_clean.cl$clust.num\n\ndata %>%\n  group_by(cluster) %>%\n  summarise(min_time = min(time),\n            max_time = max(time),\n            mean_time = mean(time))\n\ndata %>%\n  ggplot() +\n  geom_point(aes(x = cluster, y = time, color = driversex))\n\ndata %>%\n  ggplot() +\n  geom_point(aes(x = cluster, y = time, color = direction))\n```\n\n## Conclusion\n\nThere are three significant clusters in this data, including one cluster that is entirely female drivers, another that is almost entirely male drivers turning left, and a final cluster made up of vehicles all turning right.",
    "created" : 1544565777556.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2833422956",
    "id" : "83453567",
    "lastKnownWriteTime" : 1544565815,
    "last_content_update" : 1544565815190,
    "path" : "~/BZAN/Test/Report.Rmd",
    "project_path" : "Report.Rmd",
    "properties" : {
        "last_setup_crc32" : "6AFFC60Cf7087287"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}